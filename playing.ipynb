{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import model_selection \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, Perceptron, SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Definimos la carpeta donde se encuentran los datos\n",
    "\n",
    "data_folder = \"data/\"\n",
    "\n",
    "data_training = data_folder + \"adult.data\"\n",
    "data_test = data_folder + \"adult.test\"\n",
    "\n",
    "# Fijamos una lista de las columnas que tienen nuestros datos \n",
    "# de esta manera tenemos mas informaicion en los dataframes de \n",
    "# pandas\n",
    "\n",
    "headers = [\n",
    "    \"age\", \n",
    "    \"workclass\", \n",
    "    \"fnlwgt\", \n",
    "    \"education\", \n",
    "    \"education-num\", \n",
    "    \"marital-status\", \n",
    "    \"occupation\", \n",
    "    \"relationship\", \n",
    "    \"race\", \n",
    "    \"sex\", \n",
    "    \"capital-gain\",\n",
    "    \"captial-loss\", \n",
    "    \"hours-per-week\", \n",
    "    \"native-country\", \n",
    "    \"income\"\n",
    "]\n",
    "\n",
    "# leemos los datos desde el archivo de datos. Este tiene irregularidades\n",
    "# en el formato, ya que hemos visto que a veces las variables se separan \n",
    "# con espacios y otras no. Hemos optados por usar una expresi√≥n regular para solverntar\n",
    "# este problema\n",
    "\n",
    "df_train = pd.read_csv(data_training, index_col=False, delimiter=\",\", names=headers)\n",
    "df_test = pd.read_csv(data_test, index_col=False, delimiter=\",\", names=headers)\n",
    "\n",
    "# combinamos los datos que tenemos en un solo conjunto para realizar\n",
    "# el limpiado de datos\n",
    "\n",
    "df = pd.concat([df_train,df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48842</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48843 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass    fnlwgt   education  education-num  \\\n",
       "0      39          State-gov   77516.0   Bachelors           13.0   \n",
       "1      50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2      38            Private  215646.0     HS-grad            9.0   \n",
       "3      53            Private  234721.0        11th            7.0   \n",
       "4      28            Private  338409.0   Bachelors           13.0   \n",
       "...    ..                ...       ...         ...            ...   \n",
       "48838  39            Private  215419.0   Bachelors           13.0   \n",
       "48839  64                  ?  321403.0     HS-grad            9.0   \n",
       "48840  38            Private  374983.0   Bachelors           13.0   \n",
       "48841  44            Private   83891.0   Bachelors           13.0   \n",
       "48842  35       Self-emp-inc  182148.0   Bachelors           13.0   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married        Adm-clerical    Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial          Husband   \n",
       "2                 Divorced   Handlers-cleaners    Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners          Husband   \n",
       "4       Married-civ-spouse      Prof-specialty             Wife   \n",
       "...                    ...                 ...              ...   \n",
       "48838             Divorced      Prof-specialty    Not-in-family   \n",
       "48839              Widowed                   ?   Other-relative   \n",
       "48840   Married-civ-spouse      Prof-specialty          Husband   \n",
       "48841             Divorced        Adm-clerical        Own-child   \n",
       "48842   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  captial-loss  \\\n",
       "0                    White     Male        2174.0           0.0   \n",
       "1                    White     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    Black     Male           0.0           0.0   \n",
       "4                    Black   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "48838                White   Female           0.0           0.0   \n",
       "48839                Black     Male           0.0           0.0   \n",
       "48840                White     Male           0.0           0.0   \n",
       "48841   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "48842                White     Male           0.0           0.0   \n",
       "\n",
       "       hours-per-week  native-country   income  \n",
       "0                40.0   United-States    <=50K  \n",
       "1                13.0   United-States    <=50K  \n",
       "2                40.0   United-States    <=50K  \n",
       "3                40.0   United-States    <=50K  \n",
       "4                40.0            Cuba    <=50K  \n",
       "...               ...             ...      ...  \n",
       "48838            36.0   United-States   <=50K.  \n",
       "48839            40.0   United-States   <=50K.  \n",
       "48840            50.0   United-States   <=50K.  \n",
       "48841            40.0   United-States   <=50K.  \n",
       "48842            60.0   United-States    >50K.  \n",
       "\n",
       "[48843 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de valores perdidos en el conjunto de datos: occupation        2810\n",
      "workclass         2800\n",
      "native-country     858\n",
      "income               1\n",
      "hours-per-week       1\n",
      "captial-loss         1\n",
      "capital-gain         1\n",
      "sex                  1\n",
      "race                 1\n",
      "relationship         1\n",
      "marital-status       1\n",
      "education-num        1\n",
      "education            1\n",
      "fnlwgt               1\n",
      "age                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.replace('?', np.NaN)\n",
    "df = df.replace(' ?', np.NaN)\n",
    "\n",
    "# mostramos el numero de valores null que hay en el dataset\n",
    "print(\"Numero de valores perdidos en el conjunto de datos: {}\".format(\n",
    "    df.isnull().sum(axis=0).sort_values(ascending = False).head(30)))\n",
    "\n",
    "# sustituimos los valores de income por etiquetas 0 y 1\n",
    "\n",
    "\n",
    "df['income'] = df['income'].str.strip()\n",
    "df['income'] = df['income'].str.replace(\".\", \"\")\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48842</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48843 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass    fnlwgt   education  education-num  \\\n",
       "0      39          State-gov   77516.0   Bachelors           13.0   \n",
       "1      50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2      38            Private  215646.0     HS-grad            9.0   \n",
       "3      53            Private  234721.0        11th            7.0   \n",
       "4      28            Private  338409.0   Bachelors           13.0   \n",
       "...    ..                ...       ...         ...            ...   \n",
       "48838  39            Private  215419.0   Bachelors           13.0   \n",
       "48839  64                NaN  321403.0     HS-grad            9.0   \n",
       "48840  38            Private  374983.0   Bachelors           13.0   \n",
       "48841  44            Private   83891.0   Bachelors           13.0   \n",
       "48842  35       Self-emp-inc  182148.0   Bachelors           13.0   \n",
       "\n",
       "            marital-status          occupation     relationship  \\\n",
       "0            Never-married        Adm-clerical    Not-in-family   \n",
       "1       Married-civ-spouse     Exec-managerial          Husband   \n",
       "2                 Divorced   Handlers-cleaners    Not-in-family   \n",
       "3       Married-civ-spouse   Handlers-cleaners          Husband   \n",
       "4       Married-civ-spouse      Prof-specialty             Wife   \n",
       "...                    ...                 ...              ...   \n",
       "48838             Divorced      Prof-specialty    Not-in-family   \n",
       "48839              Widowed                 NaN   Other-relative   \n",
       "48840   Married-civ-spouse      Prof-specialty          Husband   \n",
       "48841             Divorced        Adm-clerical        Own-child   \n",
       "48842   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital-gain  captial-loss  \\\n",
       "0                    White     Male        2174.0           0.0   \n",
       "1                    White     Male           0.0           0.0   \n",
       "2                    White     Male           0.0           0.0   \n",
       "3                    Black     Male           0.0           0.0   \n",
       "4                    Black   Female           0.0           0.0   \n",
       "...                    ...      ...           ...           ...   \n",
       "48838                White   Female           0.0           0.0   \n",
       "48839                Black     Male           0.0           0.0   \n",
       "48840                White     Male           0.0           0.0   \n",
       "48841   Asian-Pac-Islander     Male        5455.0           0.0   \n",
       "48842                White     Male           0.0           0.0   \n",
       "\n",
       "       hours-per-week  native-country  income  \n",
       "0                40.0   United-States     0.0  \n",
       "1                13.0   United-States     0.0  \n",
       "2                40.0   United-States     0.0  \n",
       "3                40.0   United-States     0.0  \n",
       "4                40.0            Cuba     0.0  \n",
       "...               ...             ...     ...  \n",
       "48838            36.0   United-States     0.0  \n",
       "48839            40.0   United-States     0.0  \n",
       "48840            50.0   United-States     0.0  \n",
       "48841            40.0   United-States     0.0  \n",
       "48842            60.0   United-States     1.0  \n",
       "\n",
       "[48843 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de valores perdidos en el conjunto de datos: occupation        2810\n",
      "workclass         2800\n",
      "native-country     858\n",
      "income               1\n",
      "hours-per-week       1\n",
      "captial-loss         1\n",
      "capital-gain         1\n",
      "sex                  1\n",
      "race                 1\n",
      "relationship         1\n",
      "marital-status       1\n",
      "education-num        1\n",
      "education            1\n",
      "fnlwgt               1\n",
      "age                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# mostramos el numero de valores null que hay en el dataset\n",
    "print(\"Numero de valores perdidos en el conjunto de datos: {}\".format(\n",
    "    df.isnull().sum(axis=0).sort_values(ascending = False).head(30)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de datos de cada clase\n",
      "0.0    37155\n",
      "1.0    11687\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de datos de cada clase\")\n",
    "print(df.income.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '<=50K'), Text(0, 0, '>50K')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = df.income.value_counts().plot(kind=\"bar\", title=\"Numero de muestras de cada clase\", legend=True, figsize=(10,10))\n",
    "plot.set_xlabel(\"Clase\")\n",
    "plot.set_ylabel(\"N√∫mero de muestras\")\n",
    "plot.set_xticklabels( ('<=50K', '>50K'), rotation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['fnlwgt'], axis=1)\n",
    "df = df.drop(['education-num'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_categories = [\n",
    "    'workclass', \n",
    "    'education',\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"native-country\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos perdidos por columnas: \n",
      "occupation        2810\n",
      "workclass         2800\n",
      "native-country     858\n",
      "income               1\n",
      "hours-per-week       1\n",
      "captial-loss         1\n",
      "capital-gain         1\n",
      "sex                  1\n",
      "race                 1\n",
      "relationship         1\n",
      "marital-status       1\n",
      "education            1\n",
      "age                  0\n",
      "dtype: int64\n",
      "\n",
      "Datos perdidos por filas: \n",
      "32561    12\n",
      "45138     3\n",
      "20480     3\n",
      "34722     3\n",
      "3579      3\n",
      "43070     3\n",
      "39362     3\n",
      "20333     3\n",
      "35636     3\n",
      "12996     3\n",
      "3834      3\n",
      "35174     3\n",
      "23915     3\n",
      "32525     3\n",
      "30369     3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Trabajar con los datos perdidos\n",
    "\n",
    "print(\"Datos perdidos por columnas: \")\n",
    "print(df.isnull().sum(axis=0).sort_values(ascending = False).head(15))\n",
    "print(\"\\nDatos perdidos por filas: \")\n",
    "print(df.isnull().sum(axis=1).sort_values(ascending = False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48843, 13)\n",
      "29888    1\n",
      "37713    1\n",
      "40004    1\n",
      "28500    1\n",
      "29786    1\n",
      "        ..\n",
      "32391    0\n",
      "32390    0\n",
      "32389    0\n",
      "32388    0\n",
      "0        0\n",
      "Length: 46043, dtype: int64\n",
      "native-country    811\n",
      "occupation         10\n",
      "income              0\n",
      "hours-per-week      0\n",
      "captial-loss        0\n",
      "capital-gain        0\n",
      "sex                 0\n",
      "race                0\n",
      "relationship        0\n",
      "marital-status      0\n",
      "education           0\n",
      "workclass           0\n",
      "age                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "print(df2.shape)\n",
    "df.dropna(thresh=df.shape[1]-1, inplace=True, axis=0)\n",
    "print(df.isnull().sum(axis=1).sort_values(ascending = False))\n",
    "print(df.isnull().sum(axis=0).sort_values(ascending = False).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48842    0\n",
      "16248    0\n",
      "16268    0\n",
      "16267    0\n",
      "16266    0\n",
      "        ..\n",
      "32523    0\n",
      "32522    0\n",
      "32521    0\n",
      "32520    0\n",
      "0        0\n",
      "Length: 46043, dtype: int64\n",
      "income            0\n",
      "native-country    0\n",
      "hours-per-week    0\n",
      "captial-loss      0\n",
      "capital-gain      0\n",
      "sex               0\n",
      "race              0\n",
      "relationship      0\n",
      "occupation        0\n",
      "marital-status    0\n",
      "education         0\n",
      "workclass         0\n",
      "age               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = df[\"native-country\"].value_counts(normalize=True)\n",
    "missing = df[\"native-country\"].isnull()\n",
    "df.loc[missing,\"native-country\"] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\n",
    "\n",
    "s = df[\"occupation\"].value_counts(normalize=True)\n",
    "missing = df[\"occupation\"].isnull()\n",
    "df.loc[missing,\"occupation\"] = np.random.choice(s.index, size=len(df[missing]),p=s.values)\n",
    "print(df.isnull().sum(axis=1).sort_values(ascending = False))\n",
    "print(df.isnull().sum(axis=0).sort_values(ascending = False).head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o antes del conjunto de datos antes de recodificar las variables: (46043, 13)\n",
      "Tama√±o antes del conjunto de datos despues de recodificar las variables: (46043, 104)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tama√±o antes del conjunto de datos antes de recodificar las variables: {}\".format(df.shape))\n",
    "df = pd.get_dummies(data=df, columns=cols_with_categories)\n",
    "print(\"Tama√±o antes del conjunto de datos despues de recodificar las variables: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>44</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48842</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46043 rows √ó 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  capital-gain  captial-loss  hours-per-week  income  \\\n",
       "0      39        2174.0           0.0            40.0     0.0   \n",
       "1      50           0.0           0.0            13.0     0.0   \n",
       "2      38           0.0           0.0            40.0     0.0   \n",
       "3      53           0.0           0.0            40.0     0.0   \n",
       "4      28           0.0           0.0            40.0     0.0   \n",
       "...    ..           ...           ...             ...     ...   \n",
       "48837  33           0.0           0.0            40.0     0.0   \n",
       "48838  39           0.0           0.0            36.0     0.0   \n",
       "48840  38           0.0           0.0            50.0     0.0   \n",
       "48841  44        5455.0           0.0            40.0     0.0   \n",
       "48842  35           0.0           0.0            60.0     1.0   \n",
       "\n",
       "       workclass_ Federal-gov  workclass_ Local-gov  workclass_ Never-worked  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           0                     0                        0   \n",
       "3                           0                     0                        0   \n",
       "4                           0                     0                        0   \n",
       "...                       ...                   ...                      ...   \n",
       "48837                       0                     0                        0   \n",
       "48838                       0                     0                        0   \n",
       "48840                       0                     0                        0   \n",
       "48841                       0                     0                        0   \n",
       "48842                       0                     0                        0   \n",
       "\n",
       "       workclass_ Private  workclass_ Self-emp-inc  ...  \\\n",
       "0                       0                        0  ...   \n",
       "1                       0                        0  ...   \n",
       "2                       1                        0  ...   \n",
       "3                       1                        0  ...   \n",
       "4                       1                        0  ...   \n",
       "...                   ...                      ...  ...   \n",
       "48837                   1                        0  ...   \n",
       "48838                   1                        0  ...   \n",
       "48840                   1                        0  ...   \n",
       "48841                   1                        0  ...   \n",
       "48842                   0                        1  ...   \n",
       "\n",
       "       native-country_ Portugal  native-country_ Puerto-Rico  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "...                         ...                          ...   \n",
       "48837                         0                            0   \n",
       "48838                         0                            0   \n",
       "48840                         0                            0   \n",
       "48841                         0                            0   \n",
       "48842                         0                            0   \n",
       "\n",
       "       native-country_ Scotland  native-country_ South  \\\n",
       "0                             0                      0   \n",
       "1                             0                      0   \n",
       "2                             0                      0   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "...                         ...                    ...   \n",
       "48837                         0                      0   \n",
       "48838                         0                      0   \n",
       "48840                         0                      0   \n",
       "48841                         0                      0   \n",
       "48842                         0                      0   \n",
       "\n",
       "       native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "...                       ...                       ...   \n",
       "48837                       0                         0   \n",
       "48838                       0                         0   \n",
       "48840                       0                         0   \n",
       "48841                       0                         0   \n",
       "48842                       0                         0   \n",
       "\n",
       "       native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                    0                              1   \n",
       "1                                    0                              1   \n",
       "2                                    0                              1   \n",
       "3                                    0                              1   \n",
       "4                                    0                              0   \n",
       "...                                ...                            ...   \n",
       "48837                                0                              1   \n",
       "48838                                0                              1   \n",
       "48840                                0                              1   \n",
       "48841                                0                              1   \n",
       "48842                                0                              1   \n",
       "\n",
       "       native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                            0                           0  \n",
       "1                            0                           0  \n",
       "2                            0                           0  \n",
       "3                            0                           0  \n",
       "4                            0                           0  \n",
       "...                        ...                         ...  \n",
       "48837                        0                           0  \n",
       "48838                        0                           0  \n",
       "48840                        0                           0  \n",
       "48841                        0                           0  \n",
       "48842                        0                           0  \n",
       "\n",
       "[46043 rows x 104 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[df.columns.difference(['income'])], df['income']\n",
    "X, y = shuffle(X, y, random_state=SEED)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y, test_size=0.8, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = [\n",
    "    (\"var\", VarianceThreshold(0.01)),   \n",
    "    (\"standardize\", StandardScaler()),      \n",
    "    (\"lasso\", SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descripci√≥n de los datos antes y despu√©s del preprocesado\n",
      "Antes: (9208, 103)\n",
      "Despues: (9208, 48)\n"
     ]
    }
   ],
   "source": [
    "x_train_prep = p.fit_transform(train_x, train_y)\n",
    "print(\"Descripci√≥n de los datos antes y despu√©s del preprocesado\")\n",
    "print(\"Antes: {}\".format(train_x.shape))\n",
    "print(\"Despues: {}\".format(x_train_prep.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo lineal\n",
    "\n",
    "preproc_lin = [\n",
    "    (\"var\", VarianceThreshold(0.01)),   \n",
    "    (\"standardize\", StandardScaler()),      \n",
    "    (\"poly\",PolynomialFeatures(1)), \n",
    "    (\"lasso\", SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
    "]\n",
    "\n",
    "pipe_lineal = Pipeline(steps=preproc_lin+[('estimator', LogisticRegression())])\n",
    "params_lineal = {\n",
    "    'estimator':[LogisticRegression(max_iter=500)],\n",
    "    'estimator__solver':['lbfgs'],\n",
    "    'estimator__C': np.logspace(-6, 6, 4),\n",
    "    'estimator__penalty': ['l2'],\n",
    "    'poly__degree': [1,2],\n",
    "    'estimator__tol': [1e-3, 1e-4, 1e-2]\n",
    "}\n",
    "best_clf_lin = GridSearchCV(pipe_lineal, params_lineal, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  5.0min finished\n",
      "/home/yabirgb/Documents/uni/Proyecto-Final---AA/env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('poly', PolynomialFeatures(degree=1)),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator': [LogisticRegression(C=100.0, max_iter=500,\n",
       "                                                          tol=0.001)],\n",
       "                         'estimator__C': array([1.e-06, 1.e-02, 1.e+02, 1.e+06]),\n",
       "                         'estimator__penalty': ['l2'],\n",
       "                         'estimator__solver': ['lbfgs'],\n",
       "                         'estimator__tol': [0.001, 0.0001, 0.01],\n",
       "                         'poly__degree': [1, 2]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_lin.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LogisticRegression(C=100.0, max_iter=500, tol=0.001),\n",
       " 'estimator__C': 100.0,\n",
       " 'estimator__penalty': 'l2',\n",
       " 'estimator__solver': 'lbfgs',\n",
       " 'estimator__tol': 0.001,\n",
       " 'poly__degree': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_lin.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en training: 72.37175\n",
      "Precisi√≥n en test:  66.40552\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisi√≥n en training:\", round(100.0 * best_clf_lin.score(train_x, train_y), 5))\n",
    "print(\"Precisi√≥n en test: \", round(100.0 * best_clf_lin.score(test_x, test_y),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "pipe_lineal = Pipeline(steps=preproc+[('estimator', RandomForestClassifier(random_state = SEED))])\n",
    "params_lineal = {\n",
    "    'estimator':[RandomForestClassifier(random_state = SEED)],\n",
    "    'estimator__criterion': ['gini','entropy'],\n",
    "    'estimator__max_features': ['sqrt'],\n",
    "    'estimator__bootstrap':['True'],\n",
    "    'estimator__min_samples_split': [2,3,4,5]\n",
    "}\n",
    "best_clf_random = GridSearchCV(pipe_lineal, params_lineal, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator',\n",
       "                                        RandomForestClassifier(random_state=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator': [RandomForestClassifier(bootstrap='True',\n",
       "                                                              max_features='sqrt',\n",
       "                                                              min_samples_split=5,\n",
       "                                                              random_state=1)],\n",
       "                         'estimator__bootstrap': ['True'],\n",
       "                         'estimator__criterion': ['gini', 'entropy'],\n",
       "                         'estimator__max_features': ['sqrt'],\n",
       "                         'estimator__min_samples_split': [2, 3, 4, 5]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_random.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': RandomForestClassifier(bootstrap='True', max_features='sqrt',\n",
       "                        min_samples_split=5, random_state=1),\n",
       " 'estimator__bootstrap': 'True',\n",
       " 'estimator__criterion': 'gini',\n",
       " 'estimator__max_features': 'sqrt',\n",
       " 'estimator__min_samples_split': 5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en training: 90.33432\n",
      "Precisi√≥n en test:  66.77672\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisi√≥n en training:\", round(100.0 * best_clf_random.score(train_x, train_y),5))\n",
    "print(\"Precisi√≥n en test: \", round(100.0 * best_clf_random.score(test_x, test_y),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "pipe_perceptron = Pipeline(steps=preproc_lin+[('estimator', Perceptron(random_state = SEED))])\n",
    "params_perceptron = {\n",
    "    'estimator':[Perceptron(random_state = SEED)],\n",
    "    'estimator__alpha':[1.0, 1e-2, 1e-3, 1e-4, 2, 5],\n",
    "    'estimator__max_iter':[2000],\n",
    "    'estimator__tol': np.logspace(-6, 1, 3),\n",
    "    'estimator__shuffle': [True],\n",
    "    'poly__degree': [1,2]\n",
    "}\n",
    "best_clf_perceptron = GridSearchCV(pipe_perceptron, params_perceptron, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('poly', PolynomialFeatures(degree=1)),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator',\n",
       "                                        Perceptron(random_state=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator': [Perceptron(alpha=1.0, max_iter=2000,\n",
       "                                                  random_state=1, tol=1e-06)],\n",
       "                         'estimator__alpha': [1.0, 0.01, 0.001, 0.0001, 2, 5],\n",
       "                         'estimator__max_iter': [2000],\n",
       "                         'estimator__shuffle': [True],\n",
       "                         'estimator__tol': array([1.00000000e-06, 3.16227766e-03, 1.00000000e+01]),\n",
       "                         'poly__degree': [1, 2]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_perceptron.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en training: 58.02626\n",
      "Precisi√≥n en test:  57.23819\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisi√≥n en training:\", round(100.0 * best_clf_perceptron.score(train_x, train_y),5))\n",
    "print(\"Precisi√≥n en test: \", round(100.0 * best_clf_perceptron.score(test_x, test_y),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': Perceptron(alpha=1.0, max_iter=2000, random_state=1, tol=1e-06),\n",
       " 'estimator__alpha': 1.0,\n",
       " 'estimator__max_iter': 2000,\n",
       " 'estimator__shuffle': True,\n",
       " 'estimator__tol': 1e-06,\n",
       " 'poly__degree': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_perceptron.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "pipe_MLP = Pipeline(steps=preproc+[('estimator', MLPClassifier(random_state = SEED))])\n",
    "params_MLP = {\n",
    "    'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
    "    'estimator__solver': ['lbfgs'],\n",
    "    'estimator__alpha': [1.0, 1e-2, 1e-3, 1e-4, 2, 5, 10],\n",
    "    'estimator__max_fun': [20000]\n",
    "}\n",
    "best_clf_mlp = GridSearchCV(pipe_MLP, params_MLP, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:  4.1min finished\n",
      "/home/yabirgb/Documents/uni/Proyecto-Final---AA/env/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator',\n",
       "                                        MLPClassifier(random_state=1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
       "                         'estimator__alpha': [1.0, 0.01, 0.001, 0.0001, 2, 5,\n",
       "                                              10],\n",
       "                         'estimator__max_fun': [20000],\n",
       "                         'estimator__solver': ['lbfgs']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_mlp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__activation': 'logistic',\n",
       " 'estimator__alpha': 5,\n",
       " 'estimator__max_fun': 20000,\n",
       " 'estimator__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_mlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en training: 74.09133\n",
      "Precisi√≥n en test:  66.60767\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisi√≥n en training:\", round(100.0 * best_clf_mlp.score(train_x, train_y),5))\n",
    "print(\"Precisi√≥n en test: \", round(100.0 * best_clf_mlp.score(test_x, test_y),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__activation': 'logistic',\n",
       " 'estimator__alpha': 5,\n",
       " 'estimator__max_fun': 20000,\n",
       " 'estimator__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_mlp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([31.11326556, 31.17334919, 31.75682807, 31.64025636, 31.89226537,\n",
       "        31.85071669, 27.55720878, 31.28721161, 29.3553545 , 29.63539262,\n",
       "        29.41889334, 29.12743616, 29.03681192, 28.91270432, 22.96084032,\n",
       "        23.32355189, 23.43970008, 24.43036137, 23.6759016 , 18.83470507,\n",
       "        17.36485877]),\n",
       " 'std_fit_time': array([0.76623439, 0.54267133, 1.23424305, 1.21181627, 0.77325879,\n",
       "        0.50636837, 4.54499796, 1.53515726, 0.6643753 , 0.88650386,\n",
       "        1.48582689, 0.54685668, 0.55786371, 0.68489658, 0.90757629,\n",
       "        0.97464259, 1.0993097 , 0.54501507, 0.9434143 , 1.91937814,\n",
       "        0.28375155]),\n",
       " 'mean_score_time': array([0.04601889, 0.07057571, 0.05935283, 0.05630927, 0.06534562,\n",
       "        0.0489749 , 0.04240737, 0.04755592, 0.05063791, 0.05357919,\n",
       "        0.04712267, 0.04861622, 0.04792061, 0.04730473, 0.04501061,\n",
       "        0.05756221, 0.04454165, 0.04640245, 0.04424963, 0.0323482 ,\n",
       "        0.0155498 ]),\n",
       " 'std_score_time': array([0.00348264, 0.01466303, 0.01307173, 0.00832873, 0.01476435,\n",
       "        0.00661907, 0.00565273, 0.00944051, 0.00783877, 0.00804828,\n",
       "        0.00645265, 0.00730083, 0.01037847, 0.00883348, 0.00301415,\n",
       "        0.02149579, 0.00892916, 0.00253599, 0.00455398, 0.00793185,\n",
       "        0.00227139]),\n",
       " 'param_estimator__activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__alpha': masked_array(data=[1.0, 0.01, 0.001, 0.0001, 2, 5, 10, 1.0, 0.01, 0.001,\n",
       "                    0.0001, 2, 5, 10, 1.0, 0.01, 0.001, 0.0001, 2, 5, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__max_fun': masked_array(data=[20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
       "                    20000, 20000, 20000, 20000, 20000, 20000, 20000, 20000,\n",
       "                    20000, 20000, 20000, 20000, 20000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__solver': masked_array(data=['lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs', 'lbfgs',\n",
       "                    'lbfgs', 'lbfgs', 'lbfgs'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 1.0,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 0.01,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 0.001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 0.0001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 2,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 5,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 10,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 1.0,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 0.01,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 0.001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 0.0001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 2,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 5,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'tanh',\n",
       "   'estimator__alpha': 10,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 1.0,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 0.01,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 0.001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 0.0001,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 2,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 5,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator__activation': 'relu',\n",
       "   'estimator__alpha': 10,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.64261556, 0.62114537, 0.60572687, 0.58616905, 0.64759725,\n",
       "        0.66666667, 0.6504065 , 0.60681818, 0.58078603, 0.57299671,\n",
       "        0.59316428, 0.6259887 , 0.63492063, 0.64678899, 0.62542182,\n",
       "        0.62375139, 0.61899441, 0.59664804, 0.63242009, 0.65227273,\n",
       "        0.64982778]),\n",
       " 'split1_test_score': array([0.65168539, 0.61962514, 0.63238512, 0.62084257, 0.64896074,\n",
       "        0.68149883, 0.6887574 , 0.61383929, 0.59023837, 0.59471366,\n",
       "        0.5978022 , 0.63901345, 0.63815029, 0.66274971, 0.65044248,\n",
       "        0.62417582, 0.61251372, 0.62192394, 0.63928968, 0.66517357,\n",
       "        0.66974596]),\n",
       " 'split2_test_score': array([0.67340067, 0.63964951, 0.64788732, 0.65723613, 0.69898534,\n",
       "        0.70683662, 0.71578947, 0.66230937, 0.61833689, 0.62749213,\n",
       "        0.62421712, 0.65256125, 0.70536692, 0.71541057, 0.68127054,\n",
       "        0.64239829, 0.63913043, 0.63414634, 0.6880531 , 0.71111111,\n",
       "        0.72321429]),\n",
       " 'split3_test_score': array([0.63605823, 0.61980831, 0.60130719, 0.61211477, 0.64976959,\n",
       "        0.66743649, 0.64852071, 0.62008734, 0.59574468, 0.60840708,\n",
       "        0.60599334, 0.63403782, 0.64036077, 0.64464692, 0.62555066,\n",
       "        0.61105092, 0.59371614, 0.6012931 , 0.63991081, 0.64044944,\n",
       "        0.65981735]),\n",
       " 'split4_test_score': array([0.6155633 , 0.59838895, 0.59302326, 0.57990868, 0.63952096,\n",
       "        0.65850673, 0.67487685, 0.59356377, 0.5954023 , 0.61952862,\n",
       "        0.61242938, 0.59408284, 0.62409639, 0.6350365 , 0.60232558,\n",
       "        0.59545455, 0.604811  , 0.60839955, 0.60807601, 0.62693683,\n",
       "        0.65375303]),\n",
       " 'mean_test_score': array([0.64386463, 0.61972346, 0.61606595, 0.61125424, 0.65696678,\n",
       "        0.67618907, 0.67567019, 0.61932359, 0.59610165, 0.60462764,\n",
       "        0.60672126, 0.62913681, 0.648579  , 0.66092654, 0.63700222,\n",
       "        0.61936619, 0.61383314, 0.61248219, 0.64154994, 0.65918874,\n",
       "        0.67127168]),\n",
       " 'std_test_score': array([0.01895789, 0.01307094, 0.02066204, 0.02763629, 0.02132417,\n",
       "        0.0170142 , 0.02512692, 0.02323098, 0.01236098, 0.01927647,\n",
       "        0.01097779, 0.01953952, 0.02893826, 0.02866016, 0.02686275,\n",
       "        0.01558044, 0.0151949 , 0.01379178, 0.02597767, 0.02888228,\n",
       "        0.02682651]),\n",
       " 'rank_test_score': array([ 8, 12, 15, 18,  6,  1,  2, 14, 21, 20, 19, 11,  7,  4, 10, 13, 16,\n",
       "        17,  9,  5,  3], dtype=int32)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_mlp.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "pipe_SVM = Pipeline(steps=preproc+[('estimator', SVC(gamma = \"scale\", kernel=\"rbf\"))])\n",
    "params_SVM = {\n",
    "    'estimator__C': [0.1, 1, 2, 5, 7, 10],\n",
    "}\n",
    "best_clf_svm = GridSearchCV(pipe_SVM, params_SVM, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator', SVC())]),\n",
       "             n_jobs=-1, param_grid={'estimator__C': [0.1, 1, 2, 5, 7, 10]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_svm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 7}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi√≥n en training: 77.82679\n",
      "Precisi√≥n en test:  64.20312\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisi√≥n en training:\", round(100.0 * best_clf_svm.score(train_x, train_y),5))\n",
    "print(\"Precisi√≥n en test: \", round(100.0 * best_clf_svm.score(test_x, test_y),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [ {\n",
    "                'estimator':[LogisticRegression(max_iter=500)],\n",
    "                'estimator__solver':['lbfgs'],\n",
    "                'estimator__C': [100],\n",
    "                'estimator__penalty': ['l2'],\n",
    "                'estimator__tol': [0.001],\n",
    "                'poly__degree': [2]\n",
    "                },\n",
    "                {\n",
    "                'estimator': [Perceptron(random_state = SEED)],\n",
    "                'estimator__alpha': [1.0],\n",
    "                'estimator__max_iter': [2000],\n",
    "                'estimator__shuffle': [True],\n",
    "                'estimator__tol': [1e-06],\n",
    "                'poly__degree': [1]\n",
    "                },\n",
    "                {\n",
    "                'estimator': [RandomForestClassifier(random_state = SEED)],\n",
    "                'estimator__criterion': ['entropy'],\n",
    "                'estimator__max_features': ['sqrt'],\n",
    "                'estimator__bootstrap':['True'],\n",
    "                'estimator__min_samples_split': [5]\n",
    "                },\n",
    "                {\n",
    "                'estimator': [MLPClassifier(random_state = SEED)],\n",
    "                'estimator__activation': ['logistic'],\n",
    "                'estimator__solver': ['lbfgs'],\n",
    "                'estimator__alpha': [5],\n",
    "                'estimator__max_fun': [20000]\n",
    "                },\n",
    "                {\n",
    "                'estimator': [SVC()],\n",
    "                'estimator__C': [7],\n",
    "                'estimator__kernel': ['rbf'],\n",
    "                'estimator__gamma': ['scale']\n",
    "                }\n",
    "               # {'estimator':[Any_other_estimator_you_want],\n",
    "               #  'estimator__valid_param_of_your_estimator':[valid_values]\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "pipe_model = Pipeline(steps=preproc_lin+[('estimator', SVC(gamma = \"scale\", kernel=\"rbf\"))])\n",
    "\n",
    "best_clf = GridSearchCV(pipe_model, params_grid, scoring = 'f1',cv = 5, n_jobs = -1, verbose=1)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   48.0s finished\n",
      "/home/yabirgb/Documents/uni/Proyecto-Final---AA/env/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('var',\n",
       "                                        VarianceThreshold(threshold=0.01)),\n",
       "                                       ('standardize', StandardScaler()),\n",
       "                                       ('poly', PolynomialFeatures(degree=1)),\n",
       "                                       ('lasso',\n",
       "                                        SelectFromModel(estimator=LassoCV(tol=0.01))),\n",
       "                                       ('estimator', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'estimator': [LogisticRegression(C=100, max_iter=500,\n",
       "                                                           tol=0.001)],\n",
       "                          'estimator__C': [100], 'estimato...\n",
       "                          'estimator__max_features': ['sqrt'],\n",
       "                          'estimator__min_samples_split': [5]},\n",
       "                         {'estimator': [MLPClassifier(random_state=1)],\n",
       "                          'estimator__activation': ['logistic'],\n",
       "                          'estimator__alpha': [5],\n",
       "                          'estimator__max_fun': [20000],\n",
       "                          'estimator__solver': ['lbfgs']},\n",
       "                         {'estimator': [SVC()], 'estimator__C': [7],\n",
       "                          'estimator__gamma': ['scale'],\n",
       "                          'estimator__kernel': ['rbf']}],\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator': LogisticRegression(C=100, max_iter=500, tol=0.001),\n",
       " 'estimator__C': 100,\n",
       " 'estimator__penalty': 'l2',\n",
       " 'estimator__solver': 'lbfgs',\n",
       " 'estimator__tol': 0.001,\n",
       " 'poly__degree': 2}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_clf.best_estimator_.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25410  2287]\n",
      " [ 3459  5679]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([45.15931163,  1.26951361,  3.07336278, 26.14345732, 10.11378245]),\n",
       " 'std_fit_time': array([2.50197571, 0.33514061, 0.18798345, 0.70874343, 1.85163412]),\n",
       " 'mean_score_time': array([0.03783164, 0.03481932, 0.13790584, 0.03947124, 0.95961223]),\n",
       " 'std_score_time': array([0.00687727, 0.00447176, 0.02268341, 0.00668379, 0.15140292]),\n",
       " 'param_estimator': masked_array(data=[LogisticRegression(C=100, max_iter=500, tol=0.001),\n",
       "                    Perceptron(random_state=1),\n",
       "                    RandomForestClassifier(random_state=1),\n",
       "                    MLPClassifier(random_state=1), SVC()],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__C': masked_array(data=[100, --, --, --, 7],\n",
       "              mask=[False,  True,  True,  True, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__penalty': masked_array(data=['l2', --, --, --, --],\n",
       "              mask=[False,  True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__solver': masked_array(data=['lbfgs', --, --, 'lbfgs', --],\n",
       "              mask=[False,  True,  True, False,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__tol': masked_array(data=[0.001, 1e-06, --, --, --],\n",
       "              mask=[False, False,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_poly__degree': masked_array(data=[2, 1, --, --, --],\n",
       "              mask=[False, False,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__alpha': masked_array(data=[--, 1.0, --, 5, --],\n",
       "              mask=[ True, False,  True, False,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__max_iter': masked_array(data=[--, 2000, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__shuffle': masked_array(data=[--, True, --, --, --],\n",
       "              mask=[ True, False,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__bootstrap': masked_array(data=[--, --, 'True', --, --],\n",
       "              mask=[ True,  True, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__criterion': masked_array(data=[--, --, 'entropy', --, --],\n",
       "              mask=[ True,  True, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__max_features': masked_array(data=[--, --, 'sqrt', --, --],\n",
       "              mask=[ True,  True, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__min_samples_split': masked_array(data=[--, --, 5, --, --],\n",
       "              mask=[ True,  True, False,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__activation': masked_array(data=[--, --, --, 'logistic', --],\n",
       "              mask=[ True,  True,  True, False,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__max_fun': masked_array(data=[--, --, --, 20000, --],\n",
       "              mask=[ True,  True,  True, False,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__gamma': masked_array(data=[--, --, --, --, 'scale'],\n",
       "              mask=[ True,  True,  True,  True, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_estimator__kernel': masked_array(data=[--, --, --, --, 'rbf'],\n",
       "              mask=[ True,  True,  True,  True, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'estimator': LogisticRegression(C=100, max_iter=500, tol=0.001),\n",
       "   'estimator__C': 100,\n",
       "   'estimator__penalty': 'l2',\n",
       "   'estimator__solver': 'lbfgs',\n",
       "   'estimator__tol': 0.001,\n",
       "   'poly__degree': 2},\n",
       "  {'estimator': Perceptron(random_state=1),\n",
       "   'estimator__alpha': 1.0,\n",
       "   'estimator__max_iter': 2000,\n",
       "   'estimator__shuffle': True,\n",
       "   'estimator__tol': 1e-06,\n",
       "   'poly__degree': 1},\n",
       "  {'estimator': RandomForestClassifier(random_state=1),\n",
       "   'estimator__bootstrap': 'True',\n",
       "   'estimator__criterion': 'entropy',\n",
       "   'estimator__max_features': 'sqrt',\n",
       "   'estimator__min_samples_split': 5},\n",
       "  {'estimator': MLPClassifier(random_state=1),\n",
       "   'estimator__activation': 'logistic',\n",
       "   'estimator__alpha': 5,\n",
       "   'estimator__max_fun': 20000,\n",
       "   'estimator__solver': 'lbfgs'},\n",
       "  {'estimator': SVC(),\n",
       "   'estimator__C': 7,\n",
       "   'estimator__gamma': 'scale',\n",
       "   'estimator__kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.65668203, 0.63599182, 0.67128028, 0.66666667, 0.63800905]),\n",
       " 'split1_test_score': array([0.68348624, 0.6040724 , 0.68720379, 0.68149883, 0.65882353]),\n",
       " 'split2_test_score': array([0.7414966 , 0.61798942, 0.72146119, 0.70683662, 0.70506912]),\n",
       " 'split3_test_score': array([0.66898148, 0.60531697, 0.65420561, 0.66743649, 0.63754427]),\n",
       " 'split4_test_score': array([0.67068758, 0.60948081, 0.66171004, 0.65850673, 0.64311815]),\n",
       " 'mean_test_score': array([0.68426678, 0.61457028, 0.67917218, 0.67618907, 0.65651283]),\n",
       " 'std_test_score': array([0.029849  , 0.01176694, 0.02384703, 0.0170142 , 0.02547417]),\n",
       " 'rank_test_score': array([1, 5, 2, 3, 4], dtype=int32)}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68.42668, 61.45703, 67.91722, 67.61891, 65.65128]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(100*x, 5) for x in [0.68426678, 0.61457028, 0.67917218, 0.67618907, 0.65651283]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
